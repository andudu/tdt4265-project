# Project: Autonomous vehicle perception

Autonomous perception is the key application and driving force for CV/ML/DL research today. A self-driving car has to know where it is with *cm* accuracy (**localization**) and need to paint a 3D map of the real-time environment around the car based on sensor input and fusion (**perception**) in order to **control** the car. In addition, the car has to **plan** how to get from A to B. Humans drive using only their eyes (more or less) and various cameras are the key sensor used for autonomous perception today.

In this project, the goal is to **detect and track** one or more of these objects:
+ Lane lines
+ Traffic signs
+ Traffic lights
+ Pedestrians
+ Cyclists
+ Other vehicles (cars, busses, trucks, etc.)

Both traditional CV methods and more modern deep learning based methods are used.

Some labelled data will be the foundation on which to build upon and generate additional labelled data.
